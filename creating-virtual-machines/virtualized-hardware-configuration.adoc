Virtualized Hardware Configuration
----------------------------------

Fine-tuning different aspects of the hardware which are not device
related (BIOS, mainboard, …) is sometimes necessary to allow guest
operating systems to properly boot and reboot.

Machine Type
~~~~~~~~~~~~

QEMU is able to work with two different classes of chipsets for x86_64,
so called machine types. The x86_64 chipsets are i440fx (also called pc)
and q35. They are versioned based on
qemu-system-latexmath:[$ARCH, following the format `pc-$]\{machine_type}-$\{qemu_version}`, e.g.`pc-i440fx-2.10`and`pc-q35-2.10`.

KubeVirt defaults to QEMU’s newest q35 machine type. If a custom machine
type is desired, it is configurable through the following structure:

[source,yaml]
----
metadata:
  name: myvmi
spec:
  domain:
    machine:
      # This value indicates QEMU machine type.
      type: pc-q35-2.10
    resources:
      requests:
        memory: 512M
    devices:
      disks:
      - name: myimage
        disk: {}
  volumes:
    - name: myimage
      persistentVolumeClaim:
        claimName: myclaim
----

Comparison of the machine types’ internals can be found
https://wiki.qemu.org/Features/Q35[at QEMU wiki].

BIOS/UEFI
~~~~~~~~~

All virtual machines use BIOS by default for booting.

It is possible to utilize UEFI/OVMF by setting a value via `spec.firmware.bootloader`:

[source.yaml]
----
apiVersion: kubevirt.io/v1alpha3
kind: VirtualMachineInstance
metadata:
  labels:
    special: vmi-alpine-efi
  name: vmi-alpine-efi
spec:
  domain:
    devices:
      disks:
      - disk:
          bus: virtio
        name: containerdisk
    firmware:
      # this sets the bootloader type
      bootloader:
        efi: {}
----

SecureBoot is not yet supported.

SMBIOS Firmware
~~~~~~~~~~~~~~~

In order to provide a consistent view on the virtualized hardware for
the guest OS, the SMBIOS UUID can be set to a constant value via
`spec.firmware.uuid`:

[source,yaml]
----
metadata:
  name: myvmi
spec:
  domain:
    firmware:
      # this sets the UUID
      uuid: 5d307ca9-b3ef-428c-8861-06e72d69f223
    resources:
      requests:
        memory: 512M
    devices:
      disks:
      - name: myimage
        disk: {}
  volumes:
    - name: myimage
      persistentVolumeClaim:
        claimName: myclaim
----

CPU
~~~

*Note*: This is not related to scheduling decisions or resource
assignment.

Topology
^^^^^^^^

Setting the number of CPU cores is possible via `spec.domain.cpu.cores`.
The following VM will have a CPU with `3` cores:

[source,yaml]
----
metadata:
  name: myvmi
spec:
  domain:
    cpu:
      # this sets the cores
      cores: 3
    resources:
      requests:
        memory: 512M
    devices:
      disks:
      - name: myimage
        disk: {}
  volumes:
    - name: myimage
      persistentVolumeClaim:
        claimName: myclaim
----

Model
^^^^^

*Note*: Be sure that node CPU model where you run a VM, has the same or
higher CPU family.

*Note*: If CPU model wasn’t defined, the VM will have CPU model closest
to one that used on the node where the VM is running.

Setting the CPU model is possible via `spec.domain.cpu.model`. The
following VM will have a CPU with the `Conroe` model:

[source,yaml]
----
metadata:
  name: myvmi
spec:
  domain:
    cpu:
      # this sets the CPU model
      model: Conroe
...
----

You can check list of available models
https://github.com/libvirt/libvirt/blob/master/src/cpu_map/index.xml[here].

Enabling default cluster cpu model
++++++++++++++++++++++++++++++++++
To enable the default cpu model, user may add the
`default-cpu-model` field in the kubevirt-config config map.

....
apiVersion: v1
kind: ConfigMap
metadata:
  name: kubevirt-config
  namespace: kubevirt
  labels:
    kubevirt.io: ""
data:
  default-cpu-model: "EPYC"
....

Default CPU model is set when vmi doesn't have any cpu model. When vmi has cpu 
model set, then vmi's cpu model is preferred. When default cpu model is not set and vmi's cpu 
model is not set too, `host-model` will be set. Default cpu model can be changed when kubevirt is running.

CPU model special cases
+++++++++++++++++++++++

As special cases you can set `spec.domain.cpu.model` equals to: -
`host-passthrough` to passthrough CPU from the node to the VM

[source,yaml]
----
metadata:
  name: myvmi
spec:
  domain:
    cpu:
      # this passthrough the node CPU to the VM
      model: host-passthrough
...
----

* `host-model` to get CPU on the VM close to the node one

[source,yaml]
----
metadata:
  name: myvmi
spec:
  domain:
    cpu:
      # this set the VM CPU close to the node one
      model: host-model
...
----

See the https://libvirt.org/formatdomain.html#elementsCPU[CPU API
reference] for more details.

Features
^^^^^^^^

Setting CPU features is possible via `spec.domain.cpu.features` and can contain zero or more CPU features :

[source,yaml]
----
metadata:
  name: myvmi
spec:
  domain:
    cpu:
      # this sets the CPU features
      features:
      # this is the feature's name
      - name: "apic"
      # this is the feature's policy
       policy: "require"
...
----

*Note*: Policy attribute can either be omitted or contain one of the following policies: force, require, optional, disable, forbid.

*Note*: In case a policy is omitted for a feature, it will default to *require*.

Behaviour according to Policies:

- All policies will be passed to libvirt during virtual machine creation.

- In case the feature gate "CPUNodeDiscovery" is enabled and the policy is omitted or has "require" value, then the virtual machine could be scheduled only on nodes that support this feature.

- In case the feature gate "CPUNodeDiscovery" is enabled and the policy has "forbid" value, then the virtual machine would *not* be scheduled on nodes that support this feature.


Full description about features and policies can be found https://libvirt.org/formatdomain.html#elementsCPU[here].

Clock
~~~~~

Guest time
^^^^^^^^^^

Sets the virtualized hardware clock inside the VM to a specific time.
Available options are

* *utc*
* *timezone*

See the
https://kubevirt.github.io/api-reference/master/definitions.html#_v1_clock[Clock
API Reference] for all possible configuration options.

utc
+++

If `utc` is specified, the VM’s clock will be set to UTC.

[source,yaml]
----
metadata:
  name: myvmi
spec:
  domain:
    clock:
      utc: {}
    resources:
      requests:
        memory: 512M
    devices:
      disks:
      - name: myimage
        disk: {}
  volumes:
    - name: myimage
      persistentVolumeClaim:
        claimName: myclaim
----

timezone
++++++++

If `timezone` is specified, the VM’s clock will be set to the specified
local time.

[source,yaml]
----
metadata:
  name: myvmi
spec:
  domain:
    clock:
      timezone: "America/New York"
    resources:
      requests:
        memory: 512M
    devices:
      disks:
      - name: myimage
        disk: {}
  volumes:
    - name: myimage
      persistentVolumeClaim:
        claimName: myclaim
----

Timers
^^^^^^

* *pit*
* *rtc*
* *kvm*
* *hyperv*

A pretty common timer configuration for VMs looks like this:

[source,yaml]
----
metadata:
  name: myvmi
spec:
  domain:
    clock:
      utc: {}
      # here are the timer
      timer:
        hpet:
          present: false
        pit:
          tickPolicy: delay
        rtc:
          tickPolicy: catchup
        hyperv: {}
    resources:
      requests:
        memory: 512M
    devices:
      disks:
      - name: myimage
        disk: {}
  volumes:
    - name: myimage
      persistentVolumeClaim:
        claimName: myclaim
----

`hpet` is disabled,`pit` and `rtc` are configured to use a specific
`tickPolicy`. Finally, `hyperv` is made available too.

See the
https://kubevirt.github.io/api-reference/master/definitions.html#_v1_timer[Timer
API Reference] for all possible configuration options.

*Note*: Timer can be part of a machine type. Thus it may be necessary to
explicitly disable them. We may in the future decide to add them via
cluster-level defaulting, if they are part of a QEMU machine definition.

Video and Graphics Device
~~~~~~~~~~~~~~~~~~~~~~~~~

By default a minimal Video and Graphics device configuration will be
applied to the VirtualMachineInstance. The video device is `vga`
compatible and comes with a memory size of 16 MB. This device allows
connecting to the OS via `vnc`.

It is possible not attach it by setting
`spec.domain.devices.autoattachGraphicsDevice` to `false`:

[source,yaml]
----
metadata:
  name: myvmi
spec:
  domain:
    devices:
      autoattachGraphicsDevice: false
      disks:
      - name: myimage
        disk: {}
  volumes:
    - name: myimage
      persistentVolumeClaim:
        claimName: myclaim
----

VMIs without graphics and video devices are very often referenced as
`headless` VMIs.

If using a huge amount of small VMs this can be helpful to increase the
VMI density per node, since no memory needs to be reserved for video.

Features
~~~~~~~~

KubeVirt supports a range of virtualization features which may be
tweaked in order to allow non-Linux based operating systems to properly
boot. Most noteworthy are

* *acpi*
* *apic*
* *hyperv*

A common feature configuration is shown by the following example:

[source,yaml]
----
apiVersion: kubevirt.io/v1alpha3
kind: VirtualMachineInstance
metadata:
  name: myvmi
spec:
  domain:
    # typical features 
    features:
      acpi: {}
      apic: {}
      hyperv:
        relaxed: {}
        vapic: {}
        spinlocks:
          spinlocks: 8191
    resources:
      requests:
        memory: 512M
    devices:
      disks:
      - name: myimage
        disk: {}
  volumes:
    - name: myimage
      persistentVolumeClaim:
        claimname: myclaim
----

See the
https://kubevirt.github.io/api-reference/master/definitions.html#_v1_features[Features
API Reference] for all available features and configuration options.

Resources Requests and Limits
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

An optional resource request can be specified by the users to allow the
scheduler to make a better decision in finding the most suitable Node to
place the VM.

[source,yaml]
----
apiVersion: kubevirt.io/v1alpha3
kind: VirtualMachineInstance
metadata:
  name: myvmi
spec:
  domain:
    resources:
      requests:
        memory: "1Gi"
        cpu: "2"
      limits:
        memory: "2Gi"
        cpu: "1"
      disks:
      - name: myimage
        disk: {}
  volumes:
    - name: myimage
      persistentVolumeClaim:
        claimname: myclaim
----

CPU
+++

Specifying CPU limits will determine the amount of _cpu_ _shares_ set on
the control group the VM is running in, in other words, the amount of
time the VM’s CPUs can execute on the assigned resources when there is a
competition for CPU resources.

For more information please refer to
https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#how-pods-with-resource-limits-are-run[how
Pods with resource limits are run].

Memory Overhead
+++++++++++++++

Various VM resources, such as a video adapter, IOThreads, and
supplementary system software, consume additional memory from the Node,
beyond the requested memory intended for the guest OS consumption. In
order to provide a better estimate for the scheduler, this memory
overhead will be calculated and added to the requested memory.

Please see
https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#how-pods-with-resource-requests-are-scheduled[how
Pods with resource requests are scheduled] for additional information on
resource requests and limits.

Hugepages
~~~~~~~~~

KubeVirt give you possibility to use hugepages as backing memory for
your VM. You will need to provide desired amount of memory
`resources.requests.memory` and size of hugepages to use
`memory.hugepages.pageSize`, for example for x86_64 architecture it can
be `2Mi`.

[source,yaml]
----
apiVersion: kubevirt.io/v1alpha1
kind: VirtualMachine
metadata:
  name: myvm
spec:
  domain:
    resources:
      requests:
        memory: "64Mi"
    memory:
      hugepages:
        pageSize: "2Mi"
    disks:
    - name: myimage
      disk: {}
  volumes:
    - name: myimage
      persistentVolumeClaim:
        claimname: myclaim
----

In the above example the VM will have `64Mi` of memory, but instead of
regular memory it will use node hugepages of the size of `2Mi`.

Limitations
+++++++++++

* a node must have pre-allocated hugepages
* hugepages size cannot be bigger than requested memory
* requested memory must be divisible by hugepages size

Input Devices
~~~~~~~~~~~~~

Tablet
++++++

Kubevirt supports input devices. The only type which is supported is `tablet`. 
Tablet input device supports only `virtio` and `usb` bus. Bus can be empty. In that case,
`usb` will be selected.

[source,yaml]
----
apiVersion: kubevirt.io/v1alpha3
kind: VirtualMachine
metadata:
  name: myvm
spec:
  domain:
    devices:
      inputs:
      - type: tablet
        bus: virtio
        name: tablet1
      disks:
      - name: myimage
        disk: {}
  volumes:
    - name: myimage
      persistentVolumeClaim:
        claimname: myclaim
----
